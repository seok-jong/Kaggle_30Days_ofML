{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16276656",
   "metadata": {},
   "source": [
    "# Day10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32982736",
   "metadata": {},
   "source": [
    "## 1. Underfitting and Overfitting\n",
    "\n",
    "최근에 나온 성능좋은 문제도 언더피팅과 오버피팅은 중요하게 신경쓰고 해결해야 하는 문제이다. \n",
    "\n",
    "1) ```overfitting``` 이란 모델이 학습데이터에 대해서 너무 과하게 학습되어 새로운 데이터에 대해서 정확도가 떨어지는 현상을 말하며 앞에서 봤던 의사결정트리에서는 모델이 너무 깊어졌을 때 발생한다.   \n",
    "\n",
    "\n",
    "2) ```underfitting```이란 overfitting과는 반대로 모델이 학습데이터에 대해서 기본적인 특성을 구분 못할 정도로 학습이 덜 된 상황을 말하며 학습데이터의 차원이 높은데 비해 모델의 깊이가 너무 낮거나 학습이 충분히 되지 않으면 발생한다. 의사결정트리에서는 모델의 깊이가 너무 낮을 때 발생한다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a147a3a6",
   "metadata": {},
   "source": [
    "![image.png](http://i.imgur.com/AXSEOfI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03041d13",
   "metadata": {},
   "source": [
    "이러한 ```모델의 복잡도```를 상황에 맞게 설정해 주어야 한다. 이러한 작업을 하이퍼파라미터 튜닝이라고 한다. \n",
    "\n",
    "의사결정나무에서는 전체 트리의 잎 갯수를 설정하는 것을 예로 들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e979728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace2478",
   "metadata": {},
   "source": [
    "위 코드에서 작성한 함수를 이용하여 잎 갯수에 따른 모델의 성능을 살펴봄으로써 우리의 데이터에 어떤 하이퍼 파라미터가 적합한지 찾을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504bb88",
   "metadata": {},
   "source": [
    "## 2. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b14f3",
   "metadata": {},
   "source": [
    "RandomForests를 간단하게 말하자면 의사결정트리를 여러개 이용하고 각각의 결과값들을 투표형식으로 추합하여 결과를 예측하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16853f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = \"../data/melb_data.csv\"\n",
    "home_data = pd.read_csv(data_path)\n",
    "# home_data.head()\n",
    "y=home_data.Price\n",
    "x=home_data\n",
    "# x.head()\n",
    "x=x.select_dtypes(include=['int64','float64'])\n",
    "x=x.drop(columns=['BuildingArea','YearBuilt','Car'],axis=1)\n",
    "# x.head()\n",
    "\n",
    "\n",
    "train_x,val_x,train_y,val_y = train_test_split(x,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8352c4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Random Forest Model: 363.57486597938157\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit your model\n",
    "rf_model.fit(train_x,train_y)\n",
    "\n",
    "# Calculate the mean absolute error of your Random Forest model on the validation data\n",
    "predictions=rf_model.predict(val_x)\n",
    "rf_val_mae = mean_absolute_error(predictions,val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {}\".format(rf_val_mae))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41093f",
   "metadata": {},
   "source": [
    "단순히 모델을 randomForests로 바꾸었을 뿐인데 이전에 의사결정트리로 학습을 진행했을 때보다 성능이 훨씬 좋아진 것을 확인할 수 있다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
